import logging
import sys
import os
import json
import time
import re
from datetime import datetime, timezone, timedelta
from analyzer.ai_analyzer import AIAnalyzer
from database.sheets_manager import SheetsManager

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def main():
    logger.info("=" * 60)
    logger.info("æ˜ åƒæ¡ˆä»¶ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° v1.6 [æœªæ¥å¯¾å¿œãƒ»å®Œå…¨ç‰ˆ]")
    logger.info("=" * 60)
    
    try:
        from scrapers.direct_scraper import search_all_prefectures_direct
        from scrapers.content_extractor import ContentExtractor
        
        analyzer = AIAnalyzer()
        sheets_manager = SheetsManager(os.environ["SPREADSHEET_ID"], json.loads(os.environ["GCP_SERVICE_ACCOUNT"]))
        extractor = ContentExtractor()
        jst = timezone(timedelta(hours=9))
        today = datetime.now(jst).date()

        # ğŸ†• ã‚¹ãƒãƒ¼ãƒˆå†é–‹ãƒã‚§ãƒƒã‚¯: ã¾ã çµ‚ã‚ã£ã¦ã„ãªã„BatchãŒã‚ã‚‹ã‹ç¢ºèª
        batch_id = None
        url_map = {} # å†é–‹æ™‚ã¯AIã®å›ç­”å†…ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ç©ºã§OK
        
        existing_batches = analyzer.client.beta.messages.batches.list(limit=5)
        for b in existing_batches.data:
            if b.processing_status in ["in_progress", "canceling"]:
                logger.info(f"ğŸ”„ å‰å›ã®æœªå®Œäº†ãƒãƒƒãƒã‚’ç¶™ç¶šã—ã¾ã™: {b.id}")
                batch_id = b.id
                break
            elif b.processing_status == "ended" and (datetime.now(timezone.utc) - b.created_at).total_seconds() < 3600:
                logger.info(f"âœ… ç›´è¿‘ã§å®Œäº†ã—ãŸãƒãƒƒãƒã‚’ç™ºè¦‹ã—ã¾ã—ãŸ: {b.id}")
                batch_id = b.id
                break

        # æœªå®Œäº†ãƒãƒƒãƒãŒãªã„å ´åˆã®ã¿ã€æ–°è¦ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œ
        if not batch_id:
        # 1. ãƒªãƒ³ã‚¯åé›†
        logger.info("ã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘å…¨å›½ãƒªãƒ³ã‚¯åé›†é–‹å§‹")
        prefecture_results = search_all_prefectures_direct()
        all_tasks = [{"pref": p, **r} for p, rs in prefecture_results.items() for r in rs]
        logger.info(f"âœ… {len(all_tasks)}ä»¶ã®ãƒªãƒ³ã‚¯ã‚’å–å¾—")
        
        # 2. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º
        logger.info("ã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘é‡è¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºé–‹å§‹")
        batch_requests, url_map = [], {}
        for i, task in enumerate(all_tasks, 1):
            if i % 20 == 0: logger.info(f"é€²æ—: {i}/{len(all_tasks)}")
            content_data = extractor.extract(task['url'])
            if not content_data: continue
            
            cid = f"req_{i}"
            url_map[cid] = task
            batch_requests.append(analyzer.make_batch_request(cid, task['title'], content_data['content']))
        
        # 3. Batché€ä¿¡
        logger.info(f"ã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘Anthropicé€ä¿¡ ({len(batch_requests)}ä»¶)")
        batch = analyzer.client.beta.messages.batches.create(requests=batch_requests)
        batch_id = batch.id
        
        # 4. å®Œäº†å¾…æ©Ÿï¼ˆã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼å¯¾ç­–æ¸ˆï¼‰
        logger.info("ã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘AIè§£æå¾…ã¡...")
        while True:
            try:
                b_status = analyzer.client.beta.messages.batches.retrieve(batch_id)
                logger.info(f"â³ {b_status.processing_status}: {b_status.request_counts.succeeded}ä»¶å®Œäº†")
                if b_status.processing_status == "ended": break
                time.sleep(60)
            except Exception as e:
                logger.warning(f"âš ï¸ 5åˆ†å¾…æ©Ÿ... ({e})"); time.sleep(300)
        
       # 5. çµæœè§£æ
        logger.info("ã€ã‚¹ãƒ†ãƒƒãƒ—5ã€‘çµæœè§£æä¸­...")
        final_projects, stats = [], {"A": 0, "B": 0, "C": 0}
        excluded_details = []  # ğŸ†• é™¤å¤–ç†ç”±ã‚’æºœã‚ã‚‹ç®±

        for res in analyzer.client.beta.messages.batches.results(batch_id):
            if res.result.type == "succeeded":
                try:
                    res_text = res.result.message.content[0].text
                    analysis = json.loads(re.search(r'\{.*\}', res_text, re.DOTALL).group(0))
                    
                    label = analysis.get('label', 'C')
                    stats[label] = stats.get(label, 0) + 1
                    t = analysis.get('title', 'ç„¡é¡Œ')
                    
                    if label in ["A", "B"]:
                        # ğŸ†• æ¤œé–²1: å¹´åº¦ãƒã‚§ãƒƒã‚¯
                        if re.search(r"ä»¤å’Œ[5-7]|R[5-7]|202[3-5]", t) and "ä»¤å’Œ8" not in t:
                            excluded_details.append(f"âŒ éå»å¹´åº¦ã«ã¤ãé™¤å¤–: {t}")
                            continue
                        
                        # ğŸ†• æ¤œé–²2: æœŸé™åˆ‡ã‚Œãƒã‚§ãƒƒã‚¯
                        dp = analysis.get('deadline_prop', 'ä¸æ˜')
                        if dp != "ä¸æ˜":
                            m = re.search(r'(\d{4})[-/å¹´](\d{1,2})[-/æœˆ](\d{1,2})', dp)
                            if m and datetime(*map(int, m.groups())).date() < today:
                                excluded_details.append(f"âŒ æœŸé™åˆ‡ã‚Œ({dp})ã«ã¤ãé™¤å¤–: {t}")
                                continue

                        # ğŸ†• åˆæ ¼ã—ãŸã‚‚ã®ã‚’ãƒ­ã‚°ã«å‡ºã™
                        logger.info(f"âœ… åˆæ ¼åˆ¤å®š({label}): {t}")

                        analysis.update({'source_url': url_map[res.custom_id]['url'], 'prefecture': url_map[res.custom_id]['pref']})
                        final_projects.append(analysis)
                except: continue

        # ğŸ†• ãƒ«ãƒ¼ãƒ—çµ‚äº†ç›´å¾Œï¼šé™¤å¤–ãƒªã‚¹ãƒˆã‚’ã‚¬ãƒ„ãƒ³ã¨è¡¨ç¤º
        if excluded_details:
            logger.info("=" * 15 + " æœ€çµ‚æ¤œé–²ã§é™¤å¤–ã•ã‚ŒãŸæ¡ˆä»¶ãƒªã‚¹ãƒˆ " + "=" * 15)
            for detail in excluded_details:
                logger.info(detail)
            logger.info("=" * 60)
            
        logger.info(f"ğŸ“Š æœ€çµ‚çµ±è¨ˆ - A:{stats['A']}ä»¶, B:{stats['B']}ä»¶, C:{stats['C']}ä»¶")
        
        # 6. ã‚·ãƒ¼ãƒˆæ›¸ãè¾¼ã¿
        if final_projects:
            sheet_name = datetime.now(jst).strftime("æ˜ åƒæ¡ˆä»¶_%Yå¹´%mæœˆ_v16")
            sheets_manager.append_projects(sheets_manager.prepare_v12_sheet(sheet_name), final_projects)
            logger.info(f"âœ¨ å®Œäº†ï¼ {len(final_projects)}ä»¶ã‚’è¿½åŠ  (A:{stats['A']}, B:{stats['B']})")
        else: logger.warning("âš ï¸ æ–°ç€æ¡ˆä»¶ãªã—")
        
    except Exception as e: logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()
