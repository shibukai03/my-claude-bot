import logging
import sys
import os
import json
import time
import re
from datetime import datetime, timezone, timedelta
from analyzer.ai_analyzer import AIAnalyzer
from database.sheets_manager import SheetsManager

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def main():
    logger.info("=" * 60)
    logger.info("æ˜ åƒæ¡ˆä»¶ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° v1.5 [Batch API æœ€çµ‚å®Œæˆç‰ˆ]")
    logger.info("=" * 60)
    
    try:
        from scrapers.direct_scraper import search_all_prefectures_direct
        from scrapers.content_extractor import ContentExtractor
        
        analyzer = AIAnalyzer()
        sheets_manager = SheetsManager(os.environ["SPREADSHEET_ID"], json.loads(os.environ["GCP_SERVICE_ACCOUNT"]))
        extractor = ContentExtractor()
        jst = timezone(timedelta(hours=9))
        today = datetime.now(jst).date()
        
        # 1. ãƒªãƒ³ã‚¯åé›†
        logger.info("ã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘ãƒªãƒ³ã‚¯åé›†é–‹å§‹")
        prefecture_results = search_all_prefectures_direct()
        
        all_tasks = []
        for pref, results in prefecture_results.items():
            for res in results:
                res['pref'] = pref
                all_tasks.append(res)
        
        logger.info(f"âœ… {len(all_tasks)} ä»¶ã®ãƒªãƒ³ã‚¯ã‚’åé›†")
        
        # ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: æœ€åˆã®10ä»¶ã®ã¿å‡¦ç† (æœ¬ç•ªã¯ã“ã“ã‚’ False ã«)
        TEST_MODE = False
        if TEST_MODE:
            all_tasks = all_tasks[:10]
            logger.info(f"ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: {len(all_tasks)}ä»¶ã®ã¿å‡¦ç†")
        
        # 2. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º
        logger.info("ã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºé–‹å§‹")
        batch_requests = []
        url_map = {}
        
        for i, task in enumerate(all_tasks, 1):
            logger.info(f"æŠ½å‡ºä¸­ ({i}/{len(all_tasks)}): {task['title'][:30]}...")
            content_data = extractor.extract(task['url'])
            
            if not content_data:
                logger.warning(f"âš ï¸ æŠ½å‡ºå¤±æ•—: {task['url']}")
                continue
            
            custom_id = f"req_{i}"
            url_map[custom_id] = task
            req = analyzer.make_batch_request(custom_id, task['title'], content_data.get('content', ''))
            batch_requests.append(req)
        
        if not batch_requests:
            logger.warning("âŒ è§£æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # 3. Batché€ä¿¡
        logger.info(f"ã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘Anthropic Batch APIé€ä¿¡ ({len(batch_requests)}ä»¶)")
        batch = analyzer.client.beta.messages.batches.create(requests=batch_requests)
        batch_id = batch.id
        logger.info(f"âœ… Batché€ä¿¡å®Œäº† (ID: {batch_id})")
        
        # 4. å®Œäº†å¾…æ©Ÿ
        logger.info("ã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘å‡¦ç†å®Œäº†ã‚’å¾…æ©Ÿä¸­...")
        while True:
            batch_status = analyzer.client.beta.messages.batches.retrieve(batch_id)
            status = batch_status.processing_status
            counts = batch_status.request_counts
            total = counts.succeeded + counts.errored + counts.canceled + counts.expired
            
            logger.info(f"â³ {status}: {total}/{len(batch_requests)}ä»¶å®Œäº† (æˆåŠŸ:{counts.succeeded}, å¤±æ•—:{counts.errored})")
            if status == "ended": break
            time.sleep(30)
        
        # 5. çµæœè§£æ
        logger.info("ã€ã‚¹ãƒ†ãƒƒãƒ—5ã€‘çµæœå–å¾—ãƒ»è§£æé–‹å§‹")
        stats = {"A": 0, "B": 0, "C": 0, "errors": 0}
        label_c_reasons = []
        final_valid_projects = []
        
        results_response = analyzer.client.beta.messages.batches.results(batch_id)
        
        for result in results_response:
            custom_id = result.custom_id
            if result.result.type == "succeeded":
                try:
                    res_text = result.result.message.content[0].text
                    match = re.search(r'\{.*\}', res_text, re.DOTALL)
                    if not match: continue
                    analysis = json.loads(match.group(0))
                    label = analysis.get('label', 'C')
                    
                    # çµ±è¨ˆ
                    stats[label] = stats.get(label, 0) + 1
                    if label == "C":
                        label_c_reasons.append({"title": analysis.get('title', 'ä¸æ˜'), "evidence": analysis.get('evidence', 'ç†ç”±ä¸æ˜')})
                    
                    if label in ["A", "B"]:
                        d_prop = analysis.get('deadline_prop', "ä¸æ˜")
                        # æ—¥ä»˜ãƒã‚§ãƒƒã‚¯
                        if d_prop and d_prop != "ä¸æ˜":
                            date_match = re.search(r'(\d{4})[-/å¹´](\d{1,2})[-/æœˆ](\d{1,2})', d_prop)
                            if date_match:
                                y, m, d = map(int, date_match.groups())
                                if datetime(y, m, d).date() < today:
                                    logger.info(f"â© æœŸé™åˆ‡ã‚Œã«ã¤ãé™¤å¤–: {analysis.get('title')}")
                                    continue
                        
                        orig = url_map[custom_id]
                        analysis['source_url'] = orig['url']
                        analysis['prefecture'] = orig['pref']
                        final_valid_projects.append(analysis)
                        logger.info(f"âœ… åˆæ ¼: {analysis.get('title')}")
                except: stats["errors"] += 1
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
        logger.info("=" * 60)
        logger.info(f"ğŸ“Š åˆ¤å®šçµ±è¨ˆ - A:{stats['A']}ä»¶, B:{stats['B']}ä»¶, C:{stats['C']}ä»¶")
        if label_c_reasons:
            logger.info("ğŸ” é™¤å¤–ã•ã‚ŒãŸç†ç”±ï¼ˆæœ€åˆã®5ä»¶ï¼‰:")
            for r in label_c_reasons[:5]:
                logger.info(f"  - {r['title']}: {r['evidence']}")
        logger.info("=" * 60)

        # 6. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ›¸ãè¾¼ã¿
        if final_valid_projects:
            sheet_name = datetime.now(jst).strftime("æ˜ åƒæ¡ˆä»¶_%Yå¹´%mæœˆ_v15")
            worksheet = sheets_manager.prepare_v12_sheet(sheet_name)
            sheets_manager.append_projects(worksheet, final_valid_projects)
            logger.info(f"âœ¨ å®Œäº†ï¼ {len(final_valid_projects)}ä»¶ã‚’ã‚·ãƒ¼ãƒˆã«è¿½åŠ ")
        else:
            logger.warning("âš ï¸ é©åˆã™ã‚‹æ¡ˆä»¶ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
    except Exception as e:
        logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
