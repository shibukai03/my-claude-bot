"""Claude APIã‚’ä½¿ç”¨ã—ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„è§£æï¼ˆã­ã˜ã‚Œè§£æ¶ˆãƒ»æ—¥ä»˜å³æ ¼ç‰ˆï¼‰"""

import logging
import json
import os
from typing import Dict, Optional
import re

logger = logging.getLogger(__name__)

class AIAnalyzer:
    def __init__(self):
        api_key = os.getenv('ANTHROPIC_API_KEY')
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        try:
            from anthropic import Anthropic
            self.client = Anthropic(api_key=api_key)
            # å®‰å®šæ€§ã®é«˜ã„æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®š
            self.model = "claude-3-5-sonnet-20240620" 
            logger.info(f"AIAnalyzeråˆæœŸåŒ–å®Œäº†ï¼ˆãƒ¢ãƒ‡ãƒ«: {self.model}ï¼‰")
        except ImportError:
            logger.error("anthropic ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            raise
    
    def analyze_project(self, content_data: Dict) -> Optional[Dict]:
        """æ¡ˆä»¶ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è§£æ"""
        title = content_data.get('title', '')
        content = content_data.get('content', '')
        url = content_data.get('url', '')
        
        if not content or len(content.strip()) < 50:
            return None
        
        # åˆ¤å®š
        prompt = self._build_prompt(title, content, url)
        
        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=1000,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1 # ç²¾åº¦é‡è¦–ã®ãŸã‚ä½ã‚ã«è¨­å®š
            )
            
            response_text = response.content[0].text
            result = self._parse_response(response_text)
            
            if result:
                # AIåˆ¤å®šãŒTrueã®å ´åˆã®ã¿è¿”ã™
                if result.get('is_video_project'):
                    return result
            
        except Exception as e:
            logger.error(f"AIè§£æã‚¨ãƒ©ãƒ¼: {e}")
        
        return None
    
    def _build_prompt(self, title: str, content: str, url: str) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆã­ã˜ã‚Œé˜²æ­¢ãƒ»æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿å¼·åŒ–ï¼‰"""
        return f"""ä»¥ä¸‹ã®è¡Œæ”¿æ–‡æ›¸ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

**ã‚¿ã‚¤ãƒˆãƒ«**: {title}
**URL**: {url}
**æœ¬æ–‡ï¼ˆæŠœç²‹ï¼‰**:
{content[:3000]}

---
ã€åˆ†æãƒ«ãƒ¼ãƒ«ã€‘
1. ã“ã®æ–‡æ›¸ãŒã€è¡Œæ”¿ã«ã‚ˆã‚‹ã€Œæ˜ åƒåˆ¶ä½œãƒ»å‹•ç”»åˆ¶ä½œãƒ»PRå‹•ç”»ãƒ»æ’®å½±ãƒ»ãƒ©ã‚¤ãƒ–é…ä¿¡ã€ã®ã€æ°‘é–“å§”è¨—ï¼ˆå…¥æœ­ãƒ»å…¬å‹Ÿå‹ãƒ—ãƒ­ãƒï¼‰ã€‘ã«é–¢ã™ã‚‹æœ€æ–°å‹Ÿé›†ã‹åˆ¤å®šã—ã¦ãã ã•ã„ã€‚
2. **é‡è¦**: æ¤œç´¢çµæœã®ãƒ©ãƒ™ãƒ«ã«é–¢ã‚ã‚‰ãšã€æœ¬æ–‡ã®å†…å®¹ã‹ã‚‰ã€Œå®Ÿéš›ã«ç™ºæ³¨ã—ã¦ã„ã‚‹éƒ½é“åºœçœŒåã€ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚
3. ã™ã§ã«å‹Ÿé›†ãŒçµ‚äº†ã—ãŸçµæœç™ºè¡¨ã‚„ã€å˜ãªã‚‹äº‹ä¾‹ç´¹ä»‹ã€ç· åˆ‡ãŒä¸æ˜ãªã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã¯ `is_video_project: false` ã¨ã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºæƒ…å ±ã€‘
- prefecture: ç™ºæ³¨å…ƒã®æ­£ã—ã„éƒ½é“åºœçœŒåï¼ˆä¾‹ï¼šå²©æ‰‹çœŒï¼‰
- is_video_project: æ˜ åƒåˆ¶ä½œã®æ–°è¦æ¡ˆä»¶å‹Ÿé›†ã§ã‚ã‚Šã€ã‹ã¤ç· åˆ‡ãŒã€Œ2026å¹´1æœˆ16æ—¥ä»¥é™ã€ãªã‚‰ true
- deadline: ç· åˆ‡æ—¥ã‚’ YYYY-MM-DD å½¢å¼ã§ã€‚ä»¤å’Œ7å¹´ã¯2025ã€ä»¤å’Œ8å¹´ã¯2026ã€‚ä¸æ˜ãªã‚‰ "ä¸æ˜"ã€‚

ä»¥ä¸‹ã®JSONå½¢å¼ã§ã®ã¿å›ç­”ã—ã¦ãã ã•ã„:
{{
  "prefecture": "ç‰¹å®šã—ãŸéƒ½é“åºœçœŒå",
  "is_video_project": true/false,
  "title": "æ­£ç¢ºãªæ¡ˆä»¶å",
  "summary": "æ¡ˆä»¶ã®å†…å®¹ï¼ˆ2è¡Œç¨‹åº¦ï¼‰",
  "deadline": "YYYY-MM-DD ã¾ãŸã¯ ä¸æ˜",
  "application_url": "å‹Ÿé›†ãƒšãƒ¼ã‚¸ã¾ãŸã¯ä»•æ§˜æ›¸ã®URL",
  "project_type": "æ˜ åƒåˆ¶ä½œé–¢é€£"
}}
"""

    def _parse_response(self, response_text: str) -> Optional[Dict]:
        try:
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(0))
            return None
        except Exception as e:
            logger.error(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def batch_analyze(self, content_list: list) -> list:
        results = []
        logger.info(f"ğŸ¬ AIè§£æé–‹å§‹: {len(content_list)}ä»¶ã‚’å‡¦ç†")
        for content_data in content_list:
            analysis = self.analyze_project(content_data)
            if analysis:
                # å…ƒã®URLæƒ…å ±ãªã©ã‚’ãƒãƒ¼ã‚¸
                analysis['url'] = content_data.get('url')
                results.append(analysis)
        return results
